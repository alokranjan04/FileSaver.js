{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MonthyWeeklyCombinedSheets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alokranjan04/FileSaver.js/blob/master/MonthyWeeklyCombinedSheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "onz588sOX48r",
        "colab_type": "code",
        "outputId": "6a08259f-6733-4de9-cdf6-553b9edb4005",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gspread\n",
        "!pip install gspread-dataframe\n",
        "!pip install flask\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gspread \n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gspread-dataframe in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: gspread>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from gspread-dataframe) (3.1.0)\n",
            "Requirement already satisfied: pandas>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from gspread-dataframe) (0.22.0)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread>=3.0.0->gspread-dataframe) (2.18.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14.0->gspread-dataframe) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14.0->gspread-dataframe) (1.14.6)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14.0->gspread-dataframe) (2.5.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread>=3.0.0->gspread-dataframe) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread>=3.0.0->gspread-dataframe) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread>=3.0.0->gspread-dataframe) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread>=3.0.0->gspread-dataframe) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.14.0->gspread-dataframe) (1.11.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask) (2.10)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask) (0.14.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask) (7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7AVuV7NmY78p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#live\n",
        "#sheet1 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1cmSHCuPKxMUHg24OgxC72l9erMhPGUm4lL5UXd9kbek/edit?usp=drive_web&ouid=109507962615664495031\")\n",
        "\n",
        "#old\n",
        "# sheet1 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1cmSHCuPKxMUHg24OgxC72l9erMhPGUm4lL5UXd9kbek/edit#gid=1297339950\")\n",
        "# sheet2 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1Rj2Q_bzw3wQ-LhfwULIwSDHl9cUVVr1m28zHx_ngKVo/edit#gid=1256653836\")\n",
        "# dateRange = pd.date_range('1/13/2019','1/15/2019').strftime('%m/%d/%Y')\n",
        "\n",
        "# old sheet\n",
        "sheet1 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1Rj2Q_bzw3wQ-LhfwULIwSDHl9cUVVr1m28zHx_ngKVo/edit#gid=1256653836\")\n",
        "# 18-25 Jan\n",
        "sheet2 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1wTKmw2OGEittMTJLLAM1z2EPGLMQJFpfxWofNC1L72E/edit?usp=drive_web&ouid=109507962615664495031\")\n",
        "# 11 to 18 jan\n",
        "sheet3 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1TviYAlCuUnVQiXkasFeOm7myR255SncDJ-AOgNCf6cw/edit#gid=1256653836\")\n",
        "# #14th Jan Sheet\n",
        "sheet4 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1cmSHCuPKxMUHg24OgxC72l9erMhPGUm4lL5UXd9kbek/edit\")\n",
        "# # 4 to 11 jan\n",
        "sheet5 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1xDcCSveHzJJOZY33-hq2pscI9E9TZuVmDOz0kEoRvCA/edit#gid=1256653836\")\n",
        "# # 28 dec to 4 jan\n",
        "sheet6 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1NqBeb1AgbXy3I4KPUgLNlOp2TExYWdZwkL5p62nS--g/edit#gid=1256653836\")\n",
        "\n",
        "dateRange = pd.date_range('1/1/2019','1/31/2019').strftime('%m/%d/%Y')\n",
        "\n",
        "\n",
        "\n",
        "# Jan & Dec Month Data\n",
        "# sheet1 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1xDcCSveHzJJOZY33-hq2pscI9E9TZuVmDOz0kEoRvCA/edit#gid=1256653836')\n",
        "# sheet2 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1Rj2Q_bzw3wQ-LhfwULIwSDHl9cUVVr1m28zHx_ngKVo/edit#gid=1256653836')\n",
        "# sheet3 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1NqBeb1AgbXy3I4KPUgLNlOp2TExYWdZwkL5p62nS--g/edit#gid=1256653836')\n",
        "# sheet4 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1KLIRl47Q1bS3uhV0fgbqdctwjbz86R4ShxOQuc_iL7Q/edit#gid=1256653836')\n",
        "# sheet5 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1dKh-1js_kMscAyUrML2TVAAZgBI4laugr-HoYr7xCBg/edit#gid=1256653836')  \n",
        "# sheet6 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1BqMAqF5U4z5m-qRXD9BspZG5Ro_jh3x2a80KOOup_nU/edit#gid=1256653836')\n",
        "# sheet7 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1O_RbV63LpZK7KSA6nPfisRJBGX5Rm8Cq_v3gfp3TC5o/edit#gid=1256653836')\n",
        "# sheet8 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1YW39Plivd870gR2PcrTDCQgce2n87kW8qo1Ir-tRV8M/edit#gid=344622670')\n",
        "# sheet9 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1E7ZyPJzqU8Sw05e01AV6HckXh5uU-CgE8SAsxY08snU/edit#gid=1987581090')\n",
        "\n",
        "# Aug Month Data\n",
        "# sheet1 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1oFpFWqpOhVfDXE9MUlr90uNCdBGzBUqhjERT1dKBVcA/edit#gid=0')\n",
        "# sheet2 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1CDxu2AeLQRkEe8wvbRjGP_wRF1ALgKHmkUlwaO5DYjQ/edit#gid=0')\n",
        "# sheet3 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1CwdQoOxIqn5E8jtdbXzm17Bdou-IFK66TSYF6b2cNgg/edit#gid=0')\n",
        "# sheet4 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1V-f1XjZ-H5e1va4E2CTXMy94Q3nQZqr0gNcQSbJz0mg/edit#gid=0')\n",
        "# sheet5 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1pOhDH6EDScu2NXblwUjx9LoDkR1QQQC4e8VqSrlb4h8/edit#gid=0')\n",
        "\n",
        "# Sept Month Data\n",
        "# sheet1 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1pOhDH6EDScu2NXblwUjx9LoDkR1QQQC4e8VqSrlb4h8/edit#gid=0')\n",
        "# sheet2 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1NhQgtytN7BP-F-BVCI2WltpR_HLACHwzyc25QuG--qg/edit#gid=0')\n",
        "# sheet3 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1ZNTYL4EHEotTLrcYXdHOhyeOs94RBdv41JJszhzgSqA/edit#gid=0')\n",
        "# sheet4 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1mgEWMsM-sSiuFNb1oWQuWyqzPkbo7vZzbSzyLR5UtPI/edit#gid=0')\n",
        "# sheet5 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1KXhVe_DmyFR6ofqR9j99JOq67Hg3UFeLjaXMr51w_Hc/edit#gid=0')  \n",
        "\n",
        "#Nov Month Data\n",
        "# sheet1 = gc.open_by_url('https://docs.google.com/spreadsheets/d/16X67ejdovdRRdhme67PNBe3Jpk-dLePwYpv8kWaSRV8/edit#gid=0')\n",
        "# sheet2 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1v-gWlZ0vPmpGZb8KKXPkzjAcVoEgFwbNzUs2F1QZ6Dk/edit#gid=0')\n",
        "# sheet3 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1kPTrJHO0COcawvDakRJYyBg2jcWBZ3bsMtfPK5NjmD8/edit#gid=1256653836')\n",
        "# sheet4 = gc.open_by_url('https://docs.google.com/spreadsheets/d/13MOHpI784cF4A-EvHJnG_NYOtjOG5llGsPZ11xH99-Y/edit#gid=1256653836')\n",
        "# sheet5 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1ZktxJ1PyXZA72jzaisPR4FU_KYkddHdPflCYG3IJpUQ/edit#gid=1256653836')  \n",
        "# dateRange = pd.date_range('11/1/2018','11/30/2018').strftime('%m/%d/%Y')\n",
        "\n",
        "\n",
        "ws1 = sheet1.worksheet('Sheet2')\n",
        "ws2 = sheet2.worksheet('Sheet2')\n",
        "ws3 = sheet3.worksheet('Sheet2')\n",
        "ws4 = sheet4.worksheet('Sheet2')\n",
        "ws5 = sheet5.worksheet('Sheet2')\n",
        "ws6 = sheet6.worksheet('Sheet2')\n",
        "# ws6 = sheet6.worksheet('Sheet2')\n",
        "# ws7 = sheet7.worksheet('Sheet2')\n",
        "# ws8 = sheet7.worksheet('Sheet2')\n",
        "# ws9 = sheet7.worksheet('Sheet2')\n",
        "\n",
        "df1 = get_as_dataframe(ws1)\n",
        "df2 = get_as_dataframe(ws2)\n",
        "df3 = get_as_dataframe(ws3)\n",
        "df4 = get_as_dataframe(ws4)\n",
        "df5 = get_as_dataframe(ws5)\n",
        "df6 = get_as_dataframe(ws6)\n",
        "# df8 = get_as_dataframe(ws7)\n",
        "# df9 = get_as_dataframe(ws8)\n",
        "# df10 = get_as_dataframe(ws9)\n",
        "df6 = df1.append(df2).append(df3).append(df4).append(df5).append(df6)#.append(df8).append(df9).append(df10)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "df6 = df6[['Activity','Activity Time','LDAP']].dropna().drop_duplicates()\n",
        "df6[\"ActivityTimeStamp\"] =   df6[\"Activity Time\"].apply(lambda x: (convertDateFormat(x)) if  isinstance(x, str) else 0)\n",
        "df6 = df6.sort_values(by=['ActivityTimeStamp'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1f9wfAa1bMBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#convert date and time \n",
        "#input convertDateFormat('8/31/2018, 6:23:28 AM')\n",
        "#output 1535696608.0\n",
        "\n",
        "def convertDateFormat(dateValue) :\n",
        "  if(('AM' in repr(dateValue)) | ('PM' in repr(dateValue)) ): \n",
        "    if (',' not in repr(dateValue)):\n",
        "      dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%Y/%m/%d %H:%M:%S %p\").timetuple()) \n",
        "    else:  \n",
        "      try: \n",
        "        dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%m/%d/%Y, %I:%M:%S %p\").timetuple())\n",
        "      except:\n",
        "        dateForamt = time.mktime(datetime.datetime.strptime(dateValue,\"%H:%M:%S, %m/%d/%Y %p\").timetuple())\n",
        "  else:\n",
        "    if (',' not in repr(dateValue)):\n",
        "      try:\n",
        "        dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%Y/%m/%d %H:%M:%S\").timetuple()) \n",
        "      except:\n",
        "        dateForamt =0\n",
        "    else:  \n",
        "      try: \n",
        "        dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%m/%d/%Y, %I:%M:%S\").timetuple())\n",
        "      except:\n",
        "        try: \n",
        "          dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%d/%m/%Y, %I:%M:%S\").timetuple())\n",
        "        except:\n",
        "          try: \n",
        "            dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%d/%m/%Y, %H:%M:%S\").timetuple())\n",
        "          except: \n",
        "            try:   \n",
        "              dateForamt = time.mktime(datetime.datetime.strptime(dateValue,\"%I:%M:%S, %m/%d/%Y\").timetuple())\n",
        "            except:\n",
        "              try: \n",
        "                dateForamt = time.mktime(datetime.datetime.strptime(dateValue,\"%H:%M:%S, %m/%d/%Y\").timetuple())\n",
        "              except:\n",
        "                 dateForamt = time.mktime(datetime.datetime.strptime(dateValue,\"%H:%M:%S, %d/%m/%Y\").timetuple())\n",
        "  return int(dateForamt)\n",
        "\n",
        "#convert time format \n",
        "\n",
        "def convertTime(counter):\n",
        "    if (counter < 60 ):\n",
        "      return str(counter)+\" Sec\"\n",
        "    elif (counter < 3600 & counter >= 60 ):\n",
        "      return str(int(counter/60))+\" Min \"+str(int(counter%60))+\" Sec\"\n",
        "    elif (counter >= 3600 ):\n",
        "      return str(int(counter/3600))+\" Hour \"+str(int((counter/3600 - int(counter/3600))*60))+\" Min \"+str(int(((counter/3600 - int(counter/3600))*60 - int((counter/3600 - int(counter/3600))*60))*60))+\" Sec\"\n",
        "\n",
        "def getLdap(ldap, dfday):\n",
        "    dfldap = dfday[dfday['LDAP'] == ldap]\n",
        "    dfldap['TimeDiff'] =  dfldap['ActivityTimeStamp'].diff()\n",
        "    startTime =  dfldap['Activity Time'].iloc[0] if (len(dfldap[dfldap['TimeDiff']> 3600*8]) ==0) else dfldap[dfldap['TimeDiff']> 3600*8]['Activity Time'].iloc[0]\n",
        "    endTime = dfldap['Activity Time'].iloc[-1]\n",
        "    stTime =  (convertDateFormat(startTime))\n",
        "    enTime =  (convertDateFormat(endTime))\n",
        "    return {'ldap': ldap, 'start Time': startTime, 'End Time': endTime, 'Total Time':(enTime - stTime) }\n",
        "        \n",
        "\n",
        "def getData(date1):\n",
        "  time1 = int(time.mktime(datetime.datetime.strptime(date1+\", 6:30:00 AM\", \"%m/%d/%Y, %I:%M:%S %p\").timetuple()))\n",
        "  time2 = int(time1 + 86400)\n",
        "  dfday = df6[(df6[\"ActivityTimeStamp\"] <time2) & (df6[\"ActivityTimeStamp\"] > time1)]\n",
        "  dfday = dfday.dropna()\n",
        "  \n",
        "  listD= []\n",
        "  for ldap in dfday.LDAP.unique():\n",
        "    listD.append(getLdap(ldap, dfday))\n",
        "  \n",
        "  if (len(listD) > 0):\n",
        "    finalFrame = pd.DataFrame(listD)[['ldap','start Time','End Time','Total Time']].dropna()\n",
        "    finalFrameAvg = int(pd.DataFrame(listD)['Total Time'].mean(axis=0))\n",
        "    averageTimeFormat = convertTime(finalFrameAvg)\n",
        "  #return ({'LDAP Count': finalFrame[finalFrame['Total Time']> 3600]['ldap'].count(),'Average Time': finalFrameAvg,'Time Format':averageTimeFormat } if (len(listD) > 0) else {'LDAP Count':0,'Average Time':0,'Time Format':0})\n",
        "  else:\n",
        "    finalFrame = pd.DataFrame([])\n",
        "\n",
        "  return finalFrame[finalFrame['Total Time']> 3600] if(len(finalFrame)>0 ) else finalFrame\n",
        "\n",
        "    \n",
        "\n",
        "def getLdapDetails(date1):\n",
        "  time1 = int(time.mktime(datetime.datetime.strptime(date1+\", 6:30:00 AM\", \"%m/%d/%Y, %I:%M:%S %p\").timetuple()))\n",
        "  time2 = int(time1 + 86400)\n",
        "  dfday = df6[( pd.to_datetime(df6[\"ActivityTimeStamp\"], format= \"%m/%d/%Y\")  <time2) & (df6[\"ActivityTimeStamp\"] > time1)]\n",
        "  dfday = dfday.dropna()\n",
        "  \n",
        "  listD= []\n",
        "  for ldap in dfday.LDAP.unique():\n",
        "    listD.append(getLdap(ldap, dfday))\n",
        "  \n",
        "  if (len(listD) > 0):\n",
        "    finalFrame = pd.DataFrame(listD)\n",
        "    return finalFrame[finalFrame['Total Time']> 3600]\n",
        "  else:\n",
        "    return pd.DataFrame(listD)\n",
        "  \n",
        "def getNonProductiveTime(date1, ldap, precision):\n",
        "  time1 = int(time.mktime(datetime.datetime.strptime(date1+\", 6:30:00 AM\", \"%m/%d/%Y, %I:%M:%S %p\").timetuple()))\n",
        "  time2 = int(time1 + 86400)\n",
        "\n",
        "  # time1 = int(convertDateFormat(t1))\n",
        "  # time2 = int(convertDateFormat(t2))\n",
        "  dfvalue = df6\n",
        "  dataday = dfvalue[(dfvalue[\"ActivityTimeStamp\"] <time2) & (dfvalue[\"ActivityTimeStamp\"] > time1)]\n",
        "  datadayldap = dataday[dataday['LDAP']==ldap]\n",
        "  datadayldap['Time Difference'] =  datadayldap['ActivityTimeStamp'].diff(periods=-1)\n",
        "  datadayldap['Time Difference'] = datadayldap['Time Difference'].apply(lambda x: (0 if isNaN(x) else -int(x)))\n",
        "  nonprodtime = datadayldap[(datadayldap['Time Difference'] >int(precision)) & (datadayldap['Time Difference'] < 3600*7)]['Time Difference']\n",
        "  return (sum(nonprodtime))\n",
        "\n",
        "def getProdTimePerLDAP(ldap,precision):\n",
        "  sumProd = 0\n",
        "  for dateval in dateRange:\n",
        "    sumProd = sumProd + getNonProductiveTime(dateval, ldap, precision)\n",
        "  return sumProd\n",
        "\n",
        "def getProdTimePerDate(dateval, ldapRange, precision):\n",
        "  sumProd = 0\n",
        "  for ldap in ldapRange:\n",
        "    sumProd = sumProd + getNonProductiveTime(dateval, ldap, precision)\n",
        "  return sumProd\n",
        "\n",
        "ldapDateSeries = {}\n",
        "panel = pd.Panel(major_axis=range(309), minor_axis=range(495))\n",
        "def ldaDetailsIndateRange(dateRange):\n",
        "  for date in dateRange:\n",
        "    print(date)\n",
        "    ldapDateSeries[date] = getData(date)\n",
        "    panel= pd.Panel(ldapDateSeries)\n",
        "  return panel\n",
        "\n",
        "def dayperhrcalc(x,y):\n",
        "  return convertTime(int(int(x)/int(y)))\n",
        "\n",
        "def isNaN(num):\n",
        "    return num != num\n",
        "\n",
        "def getProdSheet(dateSelected):\n",
        "  import gspread \n",
        "  from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "  masterSheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1K5y5uSlXGp0plzDZV9Idsxol8tfpoR0aGEPVnKzdiJM/edit#gid=0')\n",
        "  mdf = masterSheet.worksheet('Sheet1')\n",
        "\n",
        "  masterdf = get_as_dataframe(mdf)[[\"Date\",\"KLSheetId\"]].dropna()\n",
        "  datesheetid = masterdf[   pd.to_datetime(masterdf[\"Date\"], format= \"%m/%d/%Y\") == datetime.datetime.strptime(dateSelected, \"%m/%d/%Y\") ]['KLSheetId'].iloc[0]\n",
        "\n",
        "  dSheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/'+datesheetid+'/edit#gid=0')\n",
        "  dateSheet = dSheet.worksheet('Form Responses 1')\n",
        "\n",
        "  return dateSheet#get_as_dataframe(dateSheet)[[\"Start Date\",\"Start Time\",\"Email\",\"Video Count\",\"Queue Name\"]].dropna().drop_duplicates()\n",
        "\n",
        "def getUtilization(ldap, productivityLdapQDetails):\n",
        "  utilizationTime = 0\n",
        "  #print('utilizationTime time calculating for ldap '+ldap)\n",
        "  try:\n",
        "    ldapLength = len(productivityLdapQDetails[ldap].index.tolist())\n",
        "  except:\n",
        "    ldapLength = 0 \n",
        "  for i in range(0, ldapLength):\n",
        "    q = (productivityLdapQDetails[ldap].index.tolist()[i])\n",
        "    try:\n",
        "      getQueueUtilTime = coreTmDataframe[coreTmDataframe[\"Queuse Name\"] == q][\"AHT\"].iloc[0] \n",
        "    except:\n",
        "     # print('default util time  ')\n",
        "      getQueueUtilTime =0\n",
        "    utilizationTime = float(utilizationTime) + float(getQueueUtilTime) * float(productivityLdapQDetails[ldap][q])\n",
        "    #print('util time  '+str(utilizationTime))\n",
        " \n",
        "  floatVal = float(\"{0:.2f}\".format((utilizationTime/300)*100))\n",
        "  return str(floatVal)+\"%\"\n",
        "\n",
        "def gerQTime(ldap, productivityLdapQDetails):\n",
        "  try:\n",
        "    return  productivityLdapQDetails[ldap].to_json()  \n",
        "  except:\n",
        "    return 'NA'\n",
        "\n",
        "\n",
        "def getCoreTimeOfLDAP(ldap, productivityLdapQDetails):\n",
        "  coreTime=0\n",
        "  #print('core time calculating for ldap '+ldap)\n",
        "  try:\n",
        "    ldapLength = len(productivityLdapQDetails[ldap].index.tolist())\n",
        "  except:\n",
        "    ldapLength = 0 \n",
        "  for i in range(0, ldapLength):\n",
        "    q = (productivityLdapQDetails[ldap].index.tolist()[i])\n",
        "    try:\n",
        "      getQueueCoreTime = coreTmDataframe[coreTmDataframe[\"Queuse Name\"] == q][\"ProductiveTime\"].iloc[0] \n",
        "    except:\n",
        "     # print('default core time  ')\n",
        "      getQueueCoreTime =72\n",
        "    coreTime = coreTime + int(getQueueCoreTime) * int(productivityLdapQDetails[ldap][q])\n",
        "   # print('core time  '+str(coreTime))\n",
        " \n",
        "  return coreTime\n",
        "\n",
        "def getLdapProductivity(ldap, productivityLdapDetails):\n",
        "  try:\n",
        "    return productivityLdapDetails[ldap]\n",
        "  except:\n",
        "    return 0\n",
        "finaldf =  pd.DataFrame([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ox0J0IXXuUCy",
        "colab_type": "code",
        "outputId": "e11b6513-d89f-4a66-c839-07a4c45d64c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df6.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>Activity Time</th>\n",
              "      <th>LDAP</th>\n",
              "      <th>ActivityTimeStamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4407</th>\n",
              "      <td>active</td>\n",
              "      <td>28/12/2018, 12:11:17</td>\n",
              "      <td>jongha</td>\n",
              "      <td>1545955877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4410</th>\n",
              "      <td>idle</td>\n",
              "      <td>28/12/2018, 12:11:31</td>\n",
              "      <td>jongha</td>\n",
              "      <td>1545955891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4411</th>\n",
              "      <td>active</td>\n",
              "      <td>28/12/2018, 12:11:35</td>\n",
              "      <td>jongha</td>\n",
              "      <td>1545955895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4424</th>\n",
              "      <td>idle</td>\n",
              "      <td>28/12/2018, 12:13:09</td>\n",
              "      <td>jongha</td>\n",
              "      <td>1545955989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4426</th>\n",
              "      <td>active</td>\n",
              "      <td>28/12/2018, 12:13:20</td>\n",
              "      <td>jongha</td>\n",
              "      <td>1545956000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Activity         Activity Time    LDAP  ActivityTimeStamp\n",
              "4407   active  28/12/2018, 12:11:17  jongha         1545955877\n",
              "4410     idle  28/12/2018, 12:11:31  jongha         1545955891\n",
              "4411   active  28/12/2018, 12:11:35  jongha         1545955895\n",
              "4424     idle  28/12/2018, 12:13:09  jongha         1545955989\n",
              "4426   active  28/12/2018, 12:13:20  jongha         1545956000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "metadata": {
        "id": "8pp0QpmBVAQC",
        "colab_type": "code",
        "outputId": "f6fda0e9-fd02-4f6e-b4ec-cedfdd224d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1312
        }
      },
      "cell_type": "code",
      "source": [
        "# creating dataframe \n",
        "\n",
        "import gspread \n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "\n",
        "queCoreTimeSheet  = gc.open_by_url('https://docs.google.com/spreadsheets/d/13LiUzyVd0eD3zdkExdGFMQo8-Cp9ZkH2TOKfR2ORhVY/edit#gid=142325974')\n",
        "coreTimeQdf = queCoreTimeSheet.worksheet('Sheet2')\n",
        "coreTmDataframe = get_as_dataframe(coreTimeQdf)[[\"Queuse Name\",\"ProductiveTime\",\"AHT\"]].dropna()\n",
        "precision = 500\n",
        "\n",
        "dateRange = pd.date_range('1/1/2019','1/30/2019').strftime('%m/%d/%Y')\n",
        "\n",
        "\n",
        "#dateSelected = '01/18/2019'\n",
        "for dateSelected in dateRange:\n",
        "  print(dateSelected)\n",
        "  proddf1 = getProdSheet(dateSelected)\n",
        "  productivityLdapQDetails =  get_as_dataframe(proddf1)[[\"Start Time\",\"Email\",\"Video Count\",\"Queue Name\"]].dropna().groupby(['Email','Queue Name'])['Video Count'].sum()\n",
        "  productivityLdapDetails = get_as_dataframe(proddf1)[[\"Start Time\",\"Email\",\"Video Count\"]].dropna().groupby('Email')['Video Count'].sum()\n",
        "\n",
        "  datasetfordateselected= getData(dateSelected).dropna()\n",
        "  datasetfordateselected['Time in hours'] = datasetfordateselected['Total Time'].apply(lambda x: convertTime(int(x)))\n",
        "  datasetfordateselected['Non Productive Time'] = datasetfordateselected['ldap'].apply(lambda ldap: getNonProductiveTime(dateSelected, ldap, precision) )\n",
        "  datasetfordateselected['Non Productive Time in Hours'] = datasetfordateselected['Non Productive Time'].apply(lambda x: convertTime(int(x)))\n",
        "  datasetfordateselected['Productive Time'] = datasetfordateselected['Total Time'] - datasetfordateselected['Non Productive Time']\n",
        "  datasetfordateselected['Productive Time in Hours'] = datasetfordateselected['Productive Time'].apply(lambda x: convertTime(int(x)))\n",
        "  datasetfordateselected['Volume Done']  = datasetfordateselected['ldap'].apply(lambda x: getLdapProductivity(x, productivityLdapDetails))\n",
        "  datasetfordateselected['Avg Core Time']  = datasetfordateselected['ldap'].apply(lambda ldap: getCoreTimeOfLDAP(ldap, productivityLdapQDetails))\n",
        "  datasetfordateselected['Utilization Time']  = datasetfordateselected['ldap'].apply(lambda ldap: getUtilization(ldap, productivityLdapQDetails))\n",
        "  datasetfordateselected['Queue Time Details']  = datasetfordateselected['ldap'].apply(lambda ldap: gerQTime(ldap, productivityLdapQDetails))\n",
        "  print('appending '+dateSelected+' data')\n",
        "  finaldf = finaldf.append(datasetfordateselected, ignore_index=True)"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/01/2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:104: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "appending 01/01/2019 data\n",
            "01/02/2019\n",
            "appending 01/02/2019 data\n",
            "01/03/2019\n",
            "appending 01/03/2019 data\n",
            "01/04/2019\n",
            "appending 01/04/2019 data\n",
            "01/05/2019\n",
            "appending 01/05/2019 data\n",
            "01/06/2019\n",
            "appending 01/06/2019 data\n",
            "01/07/2019\n",
            "appending 01/07/2019 data\n",
            "01/08/2019\n",
            "appending 01/08/2019 data\n",
            "01/09/2019\n",
            "appending 01/09/2019 data\n",
            "01/10/2019\n",
            "appending 01/10/2019 data\n",
            "01/11/2019\n",
            "appending 01/11/2019 data\n",
            "01/12/2019\n",
            "appending 01/12/2019 data\n",
            "01/13/2019\n",
            "appending 01/13/2019 data\n",
            "01/14/2019\n",
            "appending 01/14/2019 data\n",
            "01/15/2019\n",
            "appending 01/15/2019 data\n",
            "01/16/2019\n",
            "appending 01/16/2019 data\n",
            "01/17/2019\n",
            "appending 01/17/2019 data\n",
            "01/18/2019\n",
            "appending 01/18/2019 data\n",
            "01/19/2019\n",
            "appending 01/19/2019 data\n",
            "01/20/2019\n",
            "appending 01/20/2019 data\n",
            "01/21/2019\n",
            "appending 01/21/2019 data\n",
            "01/22/2019\n",
            "appending 01/22/2019 data\n",
            "01/23/2019\n",
            "appending 01/23/2019 data\n",
            "01/24/2019\n",
            "appending 01/24/2019 data\n",
            "01/25/2019\n",
            "appending 01/25/2019 data\n",
            "01/26/2019\n",
            "appending 01/26/2019 data\n",
            "01/27/2019\n",
            "appending 01/27/2019 data\n",
            "01/28/2019\n",
            "appending 01/28/2019 data\n",
            "01/29/2019\n",
            "appending 01/29/2019 data\n",
            "01/30/2019\n",
            "appending 01/30/2019 data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j2yuKzOKG64_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "finaldf[\"Start Date\"] = finaldf[\"start Time\"].apply(lambda x: datetime.datetime.strftime(datetime.datetime.fromtimestamp(convertDateFormat(x)), '%m/%d/%Y'))\n",
        "finaldf[\"Start Time\"] = finaldf[\"start Time\"].apply(lambda x: datetime.datetime.strftime(datetime.datetime.fromtimestamp(convertDateFormat(x)), '%H:%M:%S'))\n",
        "finaldf[\"End Date\"] = finaldf[\"End Time\"].apply(lambda x: datetime.datetime.strftime(datetime.datetime.fromtimestamp(convertDateFormat(x)), '%m/%d/%Y'))\n",
        "finaldf[\"end Time\"] = finaldf[\"End Time\"].apply(lambda x: datetime.datetime.strftime(datetime.datetime.fromtimestamp(convertDateFormat(x)), '%H:%M:%S'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0v6m-Ay2KonA",
        "colab_type": "code",
        "outputId": "efba93db-93bd-4ae9-ccec-9664d6f21a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "finaldf.head()"
      ],
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ldap</th>\n",
              "      <th>start Time</th>\n",
              "      <th>End Time</th>\n",
              "      <th>Total Time</th>\n",
              "      <th>Time in hours</th>\n",
              "      <th>Non Productive Time</th>\n",
              "      <th>Non Productive Time in Hours</th>\n",
              "      <th>Productive Time</th>\n",
              "      <th>Productive Time in Hours</th>\n",
              "      <th>Volume Done</th>\n",
              "      <th>Avg Core Time</th>\n",
              "      <th>Utilization Time</th>\n",
              "      <th>Queue Time Details</th>\n",
              "      <th>Start Date</th>\n",
              "      <th>Start Time</th>\n",
              "      <th>End Date</th>\n",
              "      <th>end Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ndaoh</td>\n",
              "      <td>1/1/2019, 8:54:56 PM</td>\n",
              "      <td>1/2/2019, 6:25:09 AM</td>\n",
              "      <td>34213</td>\n",
              "      <td>9 Hour 30 Min 12 Sec</td>\n",
              "      <td>29420</td>\n",
              "      <td>8 Hour 10 Min 20 Sec</td>\n",
              "      <td>4793</td>\n",
              "      <td>1 Hour 19 Min 53 Sec</td>\n",
              "      <td>92.0</td>\n",
              "      <td>6624</td>\n",
              "      <td>28.6%</td>\n",
              "      <td>{\"Child Safety - Kids Review - Video - Xlang -...</td>\n",
              "      <td>01/01/2019</td>\n",
              "      <td>20:54:56</td>\n",
              "      <td>01/02/2019</td>\n",
              "      <td>06:25:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rsanmut</td>\n",
              "      <td>1/1/2019, 9:12:43 PM</td>\n",
              "      <td>1/2/2019, 6:26:12 AM</td>\n",
              "      <td>33209</td>\n",
              "      <td>9 Hour 13 Min 29 Sec</td>\n",
              "      <td>13240</td>\n",
              "      <td>3 Hour 40 Min 39 Sec</td>\n",
              "      <td>19969</td>\n",
              "      <td>5 Hour 32 Min 49 Sec</td>\n",
              "      <td>93.0</td>\n",
              "      <td>6696</td>\n",
              "      <td>18.6%</td>\n",
              "      <td>{\"Child Safety - Kids Review - Video - Xlang -...</td>\n",
              "      <td>01/01/2019</td>\n",
              "      <td>21:12:43</td>\n",
              "      <td>01/02/2019</td>\n",
              "      <td>06:26:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jiwonkim</td>\n",
              "      <td>1/1/2019, 6:30:16 AM</td>\n",
              "      <td>1/1/2019, 4:16:39 PM</td>\n",
              "      <td>35183</td>\n",
              "      <td>9 Hour 46 Min 22 Sec</td>\n",
              "      <td>23757</td>\n",
              "      <td>6 Hour 35 Min 57 Sec</td>\n",
              "      <td>11426</td>\n",
              "      <td>3 Hour 10 Min 26 Sec</td>\n",
              "      <td>184.0</td>\n",
              "      <td>13248</td>\n",
              "      <td>59.33%</td>\n",
              "      <td>{\"XPol - Flagged - Comment - Korean - Prod T1\"...</td>\n",
              "      <td>01/01/2019</td>\n",
              "      <td>06:30:16</td>\n",
              "      <td>01/01/2019</td>\n",
              "      <td>16:16:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apmrajan</td>\n",
              "      <td>1/1/2019, 10:14:48 PM</td>\n",
              "      <td>1/2/2019, 6:29:49 AM</td>\n",
              "      <td>29701</td>\n",
              "      <td>8 Hour 15 Min 0 Sec</td>\n",
              "      <td>13717</td>\n",
              "      <td>3 Hour 48 Min 37 Sec</td>\n",
              "      <td>15984</td>\n",
              "      <td>4 Hour 26 Min 24 Sec</td>\n",
              "      <td>199.0</td>\n",
              "      <td>14328</td>\n",
              "      <td>23.0%</td>\n",
              "      <td>{\"Hate Speech - XSource - Comments - Mandarin ...</td>\n",
              "      <td>01/01/2019</td>\n",
              "      <td>22:14:48</td>\n",
              "      <td>01/02/2019</td>\n",
              "      <td>06:29:49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>syounghi</td>\n",
              "      <td>1/1/2019, 9:36:27 PM</td>\n",
              "      <td>1/2/2019, 6:25:21 AM</td>\n",
              "      <td>31734</td>\n",
              "      <td>8 Hour 48 Min 53 Sec</td>\n",
              "      <td>20097</td>\n",
              "      <td>5 Hour 34 Min 56 Sec</td>\n",
              "      <td>11637</td>\n",
              "      <td>3 Hour 13 Min 56 Sec</td>\n",
              "      <td>195.0</td>\n",
              "      <td>14040</td>\n",
              "      <td>97.5%</td>\n",
              "      <td>{\"XPol - Flagged - Video - Korean - Prod - CRT...</td>\n",
              "      <td>01/01/2019</td>\n",
              "      <td>21:36:27</td>\n",
              "      <td>01/02/2019</td>\n",
              "      <td>06:25:21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ldap             start Time              End Time  Total Time  \\\n",
              "0     ndaoh   1/1/2019, 8:54:56 PM  1/2/2019, 6:25:09 AM       34213   \n",
              "1   rsanmut   1/1/2019, 9:12:43 PM  1/2/2019, 6:26:12 AM       33209   \n",
              "2  jiwonkim   1/1/2019, 6:30:16 AM  1/1/2019, 4:16:39 PM       35183   \n",
              "3  apmrajan  1/1/2019, 10:14:48 PM  1/2/2019, 6:29:49 AM       29701   \n",
              "4  syounghi   1/1/2019, 9:36:27 PM  1/2/2019, 6:25:21 AM       31734   \n",
              "\n",
              "          Time in hours Non Productive Time Non Productive Time in Hours  \\\n",
              "0  9 Hour 30 Min 12 Sec               29420         8 Hour 10 Min 20 Sec   \n",
              "1  9 Hour 13 Min 29 Sec               13240         3 Hour 40 Min 39 Sec   \n",
              "2  9 Hour 46 Min 22 Sec               23757         6 Hour 35 Min 57 Sec   \n",
              "3   8 Hour 15 Min 0 Sec               13717         3 Hour 48 Min 37 Sec   \n",
              "4  8 Hour 48 Min 53 Sec               20097         5 Hour 34 Min 56 Sec   \n",
              "\n",
              "  Productive Time Productive Time in Hours  Volume Done Avg Core Time  \\\n",
              "0            4793     1 Hour 19 Min 53 Sec         92.0          6624   \n",
              "1           19969     5 Hour 32 Min 49 Sec         93.0          6696   \n",
              "2           11426     3 Hour 10 Min 26 Sec        184.0         13248   \n",
              "3           15984     4 Hour 26 Min 24 Sec        199.0         14328   \n",
              "4           11637     3 Hour 13 Min 56 Sec        195.0         14040   \n",
              "\n",
              "  Utilization Time                                 Queue Time Details  \\\n",
              "0            28.6%  {\"Child Safety - Kids Review - Video - Xlang -...   \n",
              "1            18.6%  {\"Child Safety - Kids Review - Video - Xlang -...   \n",
              "2           59.33%  {\"XPol - Flagged - Comment - Korean - Prod T1\"...   \n",
              "3            23.0%  {\"Hate Speech - XSource - Comments - Mandarin ...   \n",
              "4            97.5%  {\"XPol - Flagged - Video - Korean - Prod - CRT...   \n",
              "\n",
              "   Start Date Start Time    End Date  end Time  \n",
              "0  01/01/2019   20:54:56  01/02/2019  06:25:09  \n",
              "1  01/01/2019   21:12:43  01/02/2019  06:26:12  \n",
              "2  01/01/2019   06:30:16  01/01/2019  16:16:39  \n",
              "3  01/01/2019   22:14:48  01/02/2019  06:29:49  \n",
              "4  01/01/2019   21:36:27  01/02/2019  06:25:21  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "metadata": {
        "id": "6mGamqJS57Q-",
        "colab_type": "code",
        "outputId": "e5ab7545-8b07-4ce4-f8ed-4538b756f3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "cell_type": "code",
      "source": [
        "#insert into google sheet\n",
        "\n",
        "import gspread \n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "#pSheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/18_gAPZPQgiipdApSKlz1XwNxh_cbnvCflKCqZy70Xxk/edit#gid=1109981648')\n",
        "pSheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1QsbGztD52mnwridOtqGEtmn15JOFvJvgzchO0fDlpsI/edit#gid=0')\n",
        "wks3 = pSheet.worksheet('Sheet1')\n",
        "finaldf = finaldf.dropna()[[\"ldap\",\"Start Date\",\"Start Time\",\"End Date\",\"end Time\",\"Total Time\",\"Time in hours\",\"Non Productive Time\",\"Non Productive Time in Hours\",\"Productive Time\",\"Productive Time in Hours\",\"Avg Core Time\",\"Volume Done\",\"Utilization Time\",\"Queue Time Details\"]]\n",
        "for indx in range(0,len(finaldf.index.tolist())+1):\n",
        "  time.sleep(5)\n",
        "  if indx ==0:\n",
        "    listheader = list(finaldf)\n",
        "    wks3.insert_row(listheader, 1) \n",
        "  else:\n",
        "    print('saving the data for '+finaldf.iloc[indx-1].ldap)\n",
        "    listrow = list(finaldf.iloc[indx-1].as_matrix());\n",
        "    listrowstr = [str(i) for i in listrow]\n",
        "    wks3.insert_row(listrowstr, indx+1)\n",
        "\n",
        "lastrow = len(finaldf.index.tolist())\n",
        "listrow = list(finaldf.iloc[lastrow-1].as_matrix());\n",
        "listrowstr = [str(i) for i in listrow]\n",
        "wks3.insert_row(listrowstr, lastrow+1)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving the data for seoryuk\n",
            "saving the data for romiyah\n",
            "saving the data for seyoungk\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-222-16580b291e54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfinaldf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinaldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ldap\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"start Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"End Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Total Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Time in hours\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Non Productive Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Non Productive Time in Hours\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Productive Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Productive Time in Hours\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Avg Core Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Volume Done\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Utilization Time\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Queue Time Details\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinaldf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mindx\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mlistheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinaldf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lIEUvjhBkVag",
        "colab_type": "code",
        "outputId": "cefbeb6d-ffd0-4192-f51b-00b8db39c38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#insert into google drive \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dHyqFl_V9RgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "finaldf.to_csv('Jan2019DataUpdated.csv')\n",
        "!cp Jan2019DataUpdated.csv drive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dkVQCu0J4Fsy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# report generated from the dates from the given date range\n",
        "dfVal = ldaDetailsIndateRange(dateRange)\n",
        "\n",
        "concatdf = []\n",
        "for date in dateRange:\n",
        "  concatdf.append(dfVal[date].dropna())\n",
        "\n",
        "productivityDataFrame = pd.DataFrame(pd.concat(concatdf).groupby('ldap')['Total Time'].sum())\n",
        "productivityDataFrame = productivityDataFrame.reset_index()\n",
        "productivityDataFrame.columns=['ldap', 'Total Time']\n",
        "productivityDataFrame['Total Days'] = productivityDataFrame['ldap'].apply(lambda x:  (pd.concat(concatdf)['ldap'].value_counts().to_frame()['ldap'][x]) ) \n",
        "productivityDataFrame['Time in Hours'] = productivityDataFrame['Total Time'].apply(lambda x: convertTime(int(x)) )\n",
        "productivityDataFrame['Average Time per day'] = productivityDataFrame.apply(lambda row: dayperhrcalc(row['Total Time'], row['Total Days']), axis=1 )\n",
        "productivityDataFrame['Proctive Time'] = productivityDataFrame['Total Time'] - productivityDataFrame['ldap'].apply(lambda x: getProdTimePerLDAP(x, 400))\n",
        "productivityDataFrame['Productive Time in Hours'] = productivityDataFrame['Proctive Time'].apply(lambda x: convertTime(int(x)))\n",
        "productivityDataFrame['Average Productive Time per day'] = productivityDataFrame.apply(lambda row: dayperhrcalc(row['Proctive Time'], row['Total Days']), axis=1 )\n",
        "\n",
        "monthlyList = []\n",
        "for date in dateRange:\n",
        "  print('monthly data for date '+date)\n",
        "  val={}\n",
        "  val1 = dfVal[date]\n",
        "  val.update({\n",
        "    'date':date,\n",
        "    'LDAP Count': len(dfVal[date].dropna()),\n",
        "    'Total Time': (0 if (len(dfVal[date].dropna()) ==0) else int((dfVal[date].dropna())['Total Time'].sum())),\n",
        "    'Total Time Format': convertTime(0 if (len(dfVal[date].dropna()) ==0) else int((dfVal[date].dropna())['Total Time'].sum())),\n",
        "    'Average Time': (0 if (len(dfVal[date].dropna()) ==0) else int((dfVal[date].dropna())['Total Time'].mean())),\n",
        "    'Avg Time Format': convertTime(0 if (len(dfVal[date].dropna()) ==0) else int((dfVal[date].dropna())['Total Time'].mean())) \n",
        "     })\n",
        "  monthlyList.append(val)\n",
        "\n",
        "productivityFrame = pd.DataFrame(monthlyList)\n",
        "productivityFrame['Production Time'] = productivityFrame['Total Time']- productivityFrame['date'].apply(lambda x: getProdTimePerDate(x, dfVal[x].dropna().ldap, 400 ))\n",
        "productivityFrame['Average Production Time'] = productivityFrame['Production Time']/ productivityFrame['LDAP Count']\n",
        "productivityFrame['Average Production Time in hours'] = productivityFrame['Average Production Time'].apply(lambda x: (0 if isNaN(x) else convertTime(int(x))))\n",
        "\n",
        "productivityFrame = productivityFrame[['date','LDAP Count','Total Time','Total Time Format','Average Time','Avg Time Format','Production Time','Average Production Time','Average Production Time in hours']]   \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZddgTMbJ7JE7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Insert into Google Sheet\n",
        "\n",
        "import gspread \n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "#productivitySheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/18_gAPZPQgiipdApSKlz1XwNxh_cbnvCflKCqZy70Xxk/edit#gid=0')\n",
        "productivitySheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/18_gAPZPQgiipdApSKlz1XwNxh_cbnvCflKCqZy70Xxk/edit#gid=1318935553')\n",
        "wks = productivitySheet.worksheet('Jan1-15 Datewise Details')\n",
        "for indx in range(0,len(productivityFrame.index.tolist())):\n",
        "  if indx ==0:\n",
        "    listheader = list(productivityFrame)\n",
        "    wks.insert_row(listheader, 1) \n",
        "  else:\n",
        "    listrow = list(productivityFrame.iloc[indx-1].as_matrix());\n",
        "    listrowstr = [str(i) for i in listrow]\n",
        "    wks.insert_row(listrowstr, indx+1)\n",
        "\n",
        "lastrow =len(productivityFrame.index.tolist())\n",
        "listrow = list(productivityFrame.iloc[lastrow-1].as_matrix());\n",
        "listrowstr = [str(i) for i in listrow]\n",
        "wks.insert_row(listrowstr, lastrow+1)\n",
        "\n",
        "wks2 = productivitySheet.worksheet('Jan1-15 LDAPwise Details')\n",
        "for indx in range(0,len(productivityDataFrame.index.tolist())):\n",
        "  if indx ==0:\n",
        "    listheader = list(productivityDataFrame)\n",
        "    wks2.insert_row(listheader, 1) \n",
        "  else:\n",
        "    listrow = list(productivityDataFrame.iloc[indx-1].as_matrix());\n",
        "    listrowstr = [str(i) for i in listrow]\n",
        "    wks2.insert_row(listrowstr, indx+1)\n",
        "\n",
        "lastrow =len(productivityDataFrame.index.tolist())    \n",
        "listrow = list(productivityDataFrame.iloc[lastrow-1].as_matrix());\n",
        "listrowstr = [str(i) for i in listrow]\n",
        "wks2.insert_row(listrowstr, lastrow+1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}