{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MonthyWeeklyCombinedSheets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alokranjan04/FileSaver.js/blob/master/MonthyWeeklyCombinedSheets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "onz588sOX48r",
        "colab_type": "code",
        "outputId": "91f26394-86d1-4c0a-a611-f48155c8b78c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q gspread\n",
        "!pip install gspread-dataframe\n",
        "!pip install flask\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gspread \n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gspread-dataframe in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: gspread>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from gspread-dataframe) (3.1.0)\n",
            "Requirement already satisfied: pandas>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from gspread-dataframe) (0.22.0)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread>=3.0.0->gspread-dataframe) (2.18.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14.0->gspread-dataframe) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14.0->gspread-dataframe) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.14.0->gspread-dataframe) (1.14.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread>=3.0.0->gspread-dataframe) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread>=3.0.0->gspread-dataframe) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread>=3.0.0->gspread-dataframe) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread>=3.0.0->gspread-dataframe) (2018.11.29)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.14.0->gspread-dataframe) (1.11.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.6/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask) (0.14.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask) (7.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask) (1.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DPWk46bAPyaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7AVuV7NmY78p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#live\n",
        "#sheet1 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1cmSHCuPKxMUHg24OgxC72l9erMhPGUm4lL5UXd9kbek/edit?usp=drive_web&ouid=109507962615664495031\")\n",
        "\n",
        "#old\n",
        "# sheet1 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1cmSHCuPKxMUHg24OgxC72l9erMhPGUm4lL5UXd9kbek/edit#gid=1297339950\")\n",
        "# sheet2 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1Rj2Q_bzw3wQ-LhfwULIwSDHl9cUVVr1m28zHx_ngKVo/edit#gid=1256653836\")\n",
        "# dateRange = pd.date_range('1/13/2019','1/15/2019').strftime('%m/%d/%Y')\n",
        "\n",
        "# old sheet\n",
        "#sheet1 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1Rj2Q_bzw3wQ-LhfwULIwSDHl9cUVVr1m28zHx_ngKVo/edit#gid=1256653836\")\n",
        "# 18-25 Jan\n",
        "sheet1 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1wTKmw2OGEittMTJLLAM1z2EPGLMQJFpfxWofNC1L72E/edit?usp=drive_web&ouid=109507962615664495031\")\n",
        "# 11 to 18 jan\n",
        "# sheet5 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1TviYAlCuUnVQiXkasFeOm7myR255SncDJ-AOgNCf6cw/edit#gid=1256653836\")\n",
        "# #14th Jan Sheet\n",
        "# sheet4 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1cmSHCuPKxMUHg24OgxC72l9erMhPGUm4lL5UXd9kbek/edit\")\n",
        "# # 4 to 11 jan\n",
        "# sheet2 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1xDcCSveHzJJOZY33-hq2pscI9E9TZuVmDOz0kEoRvCA/edit#gid=1256653836\")\n",
        "# # 28 dec to 4 jan\n",
        "# sheet3 = gc.open_by_url(\"https://docs.google.com/spreadsheets/d/1NqBeb1AgbXy3I4KPUgLNlOp2TExYWdZwkL5p62nS--g/edit#gid=1256653836\")\n",
        "\n",
        "dateRange = pd.date_range('1/18/2019','1/25/2019').strftime('%m/%d/%Y')\n",
        "\n",
        "\n",
        "\n",
        "# Jan & Dec Month Data\n",
        "# sheet1 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1xDcCSveHzJJOZY33-hq2pscI9E9TZuVmDOz0kEoRvCA/edit#gid=1256653836')\n",
        "# sheet2 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1Rj2Q_bzw3wQ-LhfwULIwSDHl9cUVVr1m28zHx_ngKVo/edit#gid=1256653836')\n",
        "# sheet3 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1NqBeb1AgbXy3I4KPUgLNlOp2TExYWdZwkL5p62nS--g/edit#gid=1256653836')\n",
        "# sheet4 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1KLIRl47Q1bS3uhV0fgbqdctwjbz86R4ShxOQuc_iL7Q/edit#gid=1256653836')\n",
        "# sheet5 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1dKh-1js_kMscAyUrML2TVAAZgBI4laugr-HoYr7xCBg/edit#gid=1256653836')  \n",
        "# sheet6 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1BqMAqF5U4z5m-qRXD9BspZG5Ro_jh3x2a80KOOup_nU/edit#gid=1256653836')\n",
        "# sheet7 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1O_RbV63LpZK7KSA6nPfisRJBGX5Rm8Cq_v3gfp3TC5o/edit#gid=1256653836')\n",
        "# sheet8 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1YW39Plivd870gR2PcrTDCQgce2n87kW8qo1Ir-tRV8M/edit#gid=344622670')\n",
        "# sheet9 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1E7ZyPJzqU8Sw05e01AV6HckXh5uU-CgE8SAsxY08snU/edit#gid=1987581090')\n",
        "\n",
        "# Aug Month Data\n",
        "# sheet1 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1oFpFWqpOhVfDXE9MUlr90uNCdBGzBUqhjERT1dKBVcA/edit#gid=0')\n",
        "# sheet2 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1CDxu2AeLQRkEe8wvbRjGP_wRF1ALgKHmkUlwaO5DYjQ/edit#gid=0')\n",
        "# sheet3 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1CwdQoOxIqn5E8jtdbXzm17Bdou-IFK66TSYF6b2cNgg/edit#gid=0')\n",
        "# sheet4 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1V-f1XjZ-H5e1va4E2CTXMy94Q3nQZqr0gNcQSbJz0mg/edit#gid=0')\n",
        "# sheet5 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1pOhDH6EDScu2NXblwUjx9LoDkR1QQQC4e8VqSrlb4h8/edit#gid=0')\n",
        "\n",
        "# Sept Month Data\n",
        "# sheet1 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1pOhDH6EDScu2NXblwUjx9LoDkR1QQQC4e8VqSrlb4h8/edit#gid=0')\n",
        "# sheet2 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1NhQgtytN7BP-F-BVCI2WltpR_HLACHwzyc25QuG--qg/edit#gid=0')\n",
        "# sheet3 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1ZNTYL4EHEotTLrcYXdHOhyeOs94RBdv41JJszhzgSqA/edit#gid=0')\n",
        "# sheet4 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1mgEWMsM-sSiuFNb1oWQuWyqzPkbo7vZzbSzyLR5UtPI/edit#gid=0')\n",
        "# sheet5 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1KXhVe_DmyFR6ofqR9j99JOq67Hg3UFeLjaXMr51w_Hc/edit#gid=0')  \n",
        "\n",
        "#Nov Month Data\n",
        "# sheet1 = gc.open_by_url('https://docs.google.com/spreadsheets/d/16X67ejdovdRRdhme67PNBe3Jpk-dLePwYpv8kWaSRV8/edit#gid=0')\n",
        "# sheet2 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1v-gWlZ0vPmpGZb8KKXPkzjAcVoEgFwbNzUs2F1QZ6Dk/edit#gid=0')\n",
        "# sheet3 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1kPTrJHO0COcawvDakRJYyBg2jcWBZ3bsMtfPK5NjmD8/edit#gid=1256653836')\n",
        "# sheet4 = gc.open_by_url('https://docs.google.com/spreadsheets/d/13MOHpI784cF4A-EvHJnG_NYOtjOG5llGsPZ11xH99-Y/edit#gid=1256653836')\n",
        "# sheet5 = gc.open_by_url('https://docs.google.com/spreadsheets/d/1ZktxJ1PyXZA72jzaisPR4FU_KYkddHdPflCYG3IJpUQ/edit#gid=1256653836')  \n",
        "# dateRange = pd.date_range('11/1/2018','11/30/2018').strftime('%m/%d/%Y')\n",
        "\n",
        "\n",
        "ws1 = sheet1.worksheet('Sheet2')\n",
        "# ws2 = sheet2.worksheet('Sheet2')\n",
        "# ws3 = sheet3.worksheet('Sheet2')\n",
        "# ws4 = sheet4.worksheet('Sheet2')\n",
        "# ws5 = sheet5.worksheet('Sheet2')\n",
        "# ws6 = sheet5.worksheet('Sheet2')\n",
        "# ws6 = sheet6.worksheet('Sheet2')\n",
        "# ws7 = sheet7.worksheet('Sheet2')\n",
        "# ws8 = sheet7.worksheet('Sheet2')\n",
        "# ws9 = sheet7.worksheet('Sheet2')\n",
        "\n",
        "df1 = get_as_dataframe(ws1)\n",
        "# df2 = get_as_dataframe(ws2)\n",
        "# df3 = get_as_dataframe(ws3)\n",
        "# df4 = get_as_dataframe(ws4)\n",
        "#df5 = get_as_dataframe(ws5)\n",
        "# df7 = get_as_dataframe(ws6)\n",
        "# df8 = get_as_dataframe(ws7)\n",
        "# df9 = get_as_dataframe(ws8)\n",
        "# df10 = get_as_dataframe(ws9)\n",
        "df6 = df1#.append(df2).append(df3).append(df4).append(df5)#.append(df7)#.append(df8).append(df9).append(df10)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "df6 = df6[['Activity','Activity Time','LDAP']].dropna().drop_duplicates()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1f9wfAa1bMBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#convert date and time \n",
        "#input convertDateFormat('8/31/2018, 6:23:28 AM')\n",
        "#output 1535696608.0\n",
        "\n",
        "def convertDateFormat(dateValue) :\n",
        "  if(('AM' in repr(dateValue)) | ('PM' in repr(dateValue)) ): \n",
        "    if (',' not in repr(dateValue)):\n",
        "      dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%Y/%m/%d %H:%M:%S %p\").timetuple()) \n",
        "    else:  \n",
        "      try: \n",
        "        dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%m/%d/%Y, %I:%M:%S %p\").timetuple())\n",
        "      except:\n",
        "        dateForamt = time.mktime(datetime.datetime.strptime(dateValue,\"%H:%M:%S, %m/%d/%Y %p\").timetuple())\n",
        "  else:\n",
        "    if (',' not in repr(dateValue)):\n",
        "      try:\n",
        "        dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%Y/%m/%d %H:%M:%S\").timetuple()) \n",
        "      except:\n",
        "        dateForamt =0\n",
        "    else:  \n",
        "      try: \n",
        "        dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%m/%d/%Y, %I:%M:%S\").timetuple())\n",
        "      except:\n",
        "        try: \n",
        "          dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%d/%m/%Y, %I:%M:%S\").timetuple())\n",
        "        except:\n",
        "          try: \n",
        "            dateForamt = time.mktime(datetime.datetime.strptime(dateValue, \"%d/%m/%Y, %H:%M:%S\").timetuple())\n",
        "          except: \n",
        "            try:   \n",
        "              dateForamt = time.mktime(datetime.datetime.strptime(dateValue,\"%I:%M:%S, %m/%d/%Y\").timetuple())\n",
        "            except:\n",
        "              try: \n",
        "                dateForamt = time.mktime(datetime.datetime.strptime(dateValue,\"%H:%M:%S, %m/%d/%Y\").timetuple())\n",
        "              except:\n",
        "                 dateForamt = time.mktime(datetime.datetime.strptime(dateValue,\"%H:%M:%S, %d/%m/%Y\").timetuple())\n",
        "  return int(dateForamt)\n",
        "\n",
        "#convert time format \n",
        "\n",
        "def convertTime(counter):\n",
        "    if (counter < 60 ):\n",
        "      return str(counter)+\" Sec\"\n",
        "    elif (counter < 3600 & counter >= 60 ):\n",
        "      return str(int(counter/60))+\" Min \"+str(int(counter%60))+\" Sec\"\n",
        "    elif (counter >= 3600 ):\n",
        "      return str(int(counter/3600))+\" Hour \"+str(int((counter/3600 - int(counter/3600))*60))+\" Min \"+str(int(((counter/3600 - int(counter/3600))*60 - int((counter/3600 - int(counter/3600))*60))*60))+\" Sec\"\n",
        "\n",
        "def getLdap(ldap, dfday):\n",
        "    dfldap = dfday[dfday['LDAP'] == ldap]\n",
        "    dfldap['TimeDiff'] =  dfldap['ActivityTimeStamp'].diff()\n",
        "    startTime =  dfldap['Activity Time'].iloc[0] if (len(dfldap[dfldap['TimeDiff']> 3600*8]) ==0) else dfldap[dfldap['TimeDiff']> 3600*8]['Activity Time'].iloc[0]\n",
        "    endTime = dfldap['Activity Time'].iloc[-1]\n",
        "    stTime =  (convertDateFormat(startTime))\n",
        "    enTime =  (convertDateFormat(endTime))\n",
        "    return {'ldap': ldap, 'start Time': startTime, 'End Time': endTime, 'Total Time':(enTime - stTime) }\n",
        "        \n",
        "\n",
        "def getData(date1):\n",
        "  time1 = int(time.mktime(datetime.datetime.strptime(date1+\", 6:30:00 AM\", \"%m/%d/%Y, %I:%M:%S %p\").timetuple()))\n",
        "  time2 = int(time1 + 86400)\n",
        "  dfday = df6[(df6[\"ActivityTimeStamp\"] <time2) & (df6[\"ActivityTimeStamp\"] > time1)]\n",
        "  dfday = dfday.dropna()\n",
        "  \n",
        "  listD= []\n",
        "  for ldap in dfday.LDAP.unique():\n",
        "    listD.append(getLdap(ldap, dfday))\n",
        "  \n",
        "  if (len(listD) > 0):\n",
        "    finalFrame = pd.DataFrame(listD)[['ldap','start Time','End Time','Total Time']].dropna()\n",
        "    finalFrameAvg = int(pd.DataFrame(listD)['Total Time'].mean(axis=0))\n",
        "    averageTimeFormat = convertTime(finalFrameAvg)\n",
        "  #return ({'LDAP Count': finalFrame[finalFrame['Total Time']> 3600]['ldap'].count(),'Average Time': finalFrameAvg,'Time Format':averageTimeFormat } if (len(listD) > 0) else {'LDAP Count':0,'Average Time':0,'Time Format':0})\n",
        "  else:\n",
        "    finalFrame = pd.DataFrame([])\n",
        "\n",
        "  return finalFrame[finalFrame['Total Time']> 3600] if(len(finalFrame)>0 ) else finalFrame\n",
        "\n",
        "    \n",
        "\n",
        "def getLdapDetails(date1):\n",
        "  time1 = int(time.mktime(datetime.datetime.strptime(date1+\", 6:30:00 AM\", \"%m/%d/%Y, %I:%M:%S %p\").timetuple()))\n",
        "  time2 = int(time1 + 86400)\n",
        "  dfday = df6[( pd.to_datetime(df6[\"ActivityTimeStamp\"], format= \"%m/%d/%Y\")  <time2) & (df6[\"ActivityTimeStamp\"] > time1)]\n",
        "  dfday = dfday.dropna()\n",
        "  \n",
        "  listD= []\n",
        "  for ldap in dfday.LDAP.unique():\n",
        "    listD.append(getLdap(ldap, dfday))\n",
        "  \n",
        "  if (len(listD) > 0):\n",
        "    finalFrame = pd.DataFrame(listD)\n",
        "    return finalFrame[finalFrame['Total Time']> 3600]\n",
        "  else:\n",
        "    return pd.DataFrame(listD)\n",
        "  \n",
        "def getNonProductiveTime(date1, ldap, precision):\n",
        "  time1 = int(time.mktime(datetime.datetime.strptime(date1+\", 6:30:00 AM\", \"%m/%d/%Y, %I:%M:%S %p\").timetuple()))\n",
        "  time2 = int(time1 + 86400)\n",
        "\n",
        "  # time1 = int(convertDateFormat(t1))\n",
        "  # time2 = int(convertDateFormat(t2))\n",
        "  dfvalue = df6\n",
        "  dataday = dfvalue[(dfvalue[\"ActivityTimeStamp\"] <time2) & (dfvalue[\"ActivityTimeStamp\"] > time1)]\n",
        "  datadayldap = dataday[dataday['LDAP']==ldap]\n",
        "  datadayldap['Time Difference'] =  datadayldap['ActivityTimeStamp'].diff(periods=-1)\n",
        "  datadayldap['Time Difference'] = datadayldap['Time Difference'].apply(lambda x: (0 if isNaN(x) else -int(x)))\n",
        "  nonprodtime = datadayldap[(datadayldap['Time Difference'] >int(precision)) & (datadayldap['Time Difference'] < 3600*7)]['Time Difference']\n",
        "  return (sum(nonprodtime))\n",
        "\n",
        "def getProdTimePerLDAP(ldap,precision):\n",
        "  sumProd = 0\n",
        "  for dateval in dateRange:\n",
        "    sumProd = sumProd + getNonProductiveTime(dateval, ldap, precision)\n",
        "  return sumProd\n",
        "\n",
        "def getProdTimePerDate(dateval, ldapRange, precision):\n",
        "  sumProd = 0\n",
        "  for ldap in ldapRange:\n",
        "    sumProd = sumProd + getNonProductiveTime(dateval, ldap, precision)\n",
        "  return sumProd\n",
        "\n",
        "ldapDateSeries = {}\n",
        "panel = pd.Panel(major_axis=range(309), minor_axis=range(495))\n",
        "def ldaDetailsIndateRange(dateRange):\n",
        "  for date in dateRange:\n",
        "    print(date)\n",
        "    ldapDateSeries[date] = getData(date)\n",
        "    panel= pd.Panel(ldapDateSeries)\n",
        "  return panel\n",
        "\n",
        "def dayperhrcalc(x,y):\n",
        "  return convertTime(int(int(x)/int(y)))\n",
        "\n",
        "def isNaN(num):\n",
        "    return num != num\n",
        "\n",
        "def getLdapProductivity(ldap):\n",
        "  try:\n",
        "    return productivityLdapDetails[ldap]\n",
        "  except:\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tJdlYY4uAald",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dateRange = pd.date_range('1/18/2019','1/25/2019').strftime('%m/%d/%Y')\n",
        "df6[\"ActivityTimeStamp\"] =   df6[\"Activity Time\"].apply(lambda x: (convertDateFormat(x)) if  isinstance(x, str) else 0)\n",
        "df6 = df6.sort_values(by=['ActivityTimeStamp'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2UCT5nDSEmS",
        "colab_type": "code",
        "outputId": "9b19a3b1-d5ff-4a8f-af17-7612b0152ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "dfVal = ldaDetailsIndateRange(dateRange)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/18/2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
            "Panel is deprecated and will be removed in a future version.\n",
            "The recommended way to represent these types of 3-dimensional data are with a MultiIndex on a DataFrame, via the Panel.to_frame() method\n",
            "Alternatively, you can use the xarray package http://xarray.pydata.org/en/stable/.\n",
            "Pandas provides a `.to_xarray()` method to help automate this conversion.\n",
            "\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "01/19/2019\n",
            "01/20/2019\n",
            "01/21/2019\n",
            "01/22/2019\n",
            "01/23/2019\n",
            "01/24/2019\n",
            "01/25/2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3zEtJrSKCQFp",
        "colab_type": "code",
        "outputId": "03578b81-074a-4f41-f2ef-44debbe83ed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "# report generated from the dates from the given date range\n",
        "\n",
        "concatdf = []\n",
        "for date in dateRange:\n",
        "  concatdf.append(dfVal[date].dropna())\n",
        "\n",
        "productivityDataFrame = pd.DataFrame(pd.concat(concatdf).groupby('ldap')['Total Time'].sum())\n",
        "productivityDataFrame = productivityDataFrame.reset_index()\n",
        "productivityDataFrame.columns=['ldap', 'Total Time']\n",
        "productivityDataFrame['Total Days'] = productivityDataFrame['ldap'].apply(lambda x:  (pd.concat(concatdf)['ldap'].value_counts().to_frame()['ldap'][x]) ) \n",
        "productivityDataFrame['Time in Hours'] = productivityDataFrame['Total Time'].apply(lambda x: convertTime(int(x)) )\n",
        "productivityDataFrame['Average Time per day'] = productivityDataFrame.apply(lambda row: dayperhrcalc(row['Total Time'], row['Total Days']), axis=1 )\n",
        "productivityDataFrame['Proctive Time'] = productivityDataFrame['Total Time'] - productivityDataFrame['ldap'].apply(lambda x: getProdTimePerLDAP(x, 400))\n",
        "productivityDataFrame['Productive Time in Hours'] = productivityDataFrame['Proctive Time'].apply(lambda x: convertTime(int(x)))\n",
        "productivityDataFrame['Average Productive Time per day'] = productivityDataFrame.apply(lambda row: dayperhrcalc(row['Proctive Time'], row['Total Days']), axis=1 )\n",
        "\n",
        "monthlyList = []\n",
        "for date in dateRange:\n",
        "  print('monthly data for date '+date)\n",
        "  val={}\n",
        "  val1 = dfVal[date]\n",
        "  val.update({\n",
        "    'date':date,\n",
        "    'LDAP Count': len(dfVal[date].dropna()),\n",
        "    'Total Time': (0 if (len(dfVal[date].dropna()) ==0) else int((dfVal[date].dropna())['Total Time'].sum())),\n",
        "    'Total Time Format': convertTime(0 if (len(dfVal[date].dropna()) ==0) else int((dfVal[date].dropna())['Total Time'].sum())),\n",
        "    'Average Time': (0 if (len(dfVal[date].dropna()) ==0) else int((dfVal[date].dropna())['Total Time'].mean())),\n",
        "    'Avg Time Format': convertTime(0 if (len(dfVal[date].dropna()) ==0) else int((dfVal[date].dropna())['Total Time'].mean())) \n",
        "     })\n",
        "  monthlyList.append(val)\n",
        "\n",
        "productivityFrame = pd.DataFrame(monthlyList)\n",
        "productivityFrame['Production Time'] = productivityFrame['Total Time']- productivityFrame['date'].apply(lambda x: getProdTimePerDate(x, dfVal[x].dropna().ldap, 400 ))\n",
        "productivityFrame['Average Production Time'] = productivityFrame['Production Time']/ productivityFrame['LDAP Count']\n",
        "productivityFrame['Average Production Time in hours'] = productivityFrame['Average Production Time'].apply(lambda x: (0 if isNaN(x) else convertTime(int(x))))\n",
        "\n",
        "productivityFrame = productivityFrame[['date','LDAP Count','Total Time','Total Time Format','Average Time','Avg Time Format','Production Time','Average Production Time','Average Production Time in hours']]   \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:104: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "monthly data for date 01/17/2019\n",
            "monthly data for date 01/18/2019\n",
            "monthly data for date 01/19/2019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L4lXDLnVeK_r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def getProdSheet(dateSelected):\n",
        "  import gspread \n",
        "  from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "  masterSheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/1K5y5uSlXGp0plzDZV9Idsxol8tfpoR0aGEPVnKzdiJM/edit#gid=0')\n",
        "  mdf = masterSheet.worksheet('Sheet1')\n",
        "\n",
        "  masterdf = get_as_dataframe(mdf)[[\"Date\",\"KLSheetId\"]].dropna()\n",
        "  datesheetid = masterdf[   pd.to_datetime(masterdf[\"Date\"], format= \"%m/%d/%Y\") == datetime.datetime.strptime(dateSelected, \"%m/%d/%Y\") ]['KLSheetId'].iloc[0]\n",
        "\n",
        "  dSheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/'+datesheetid+'/edit#gid=0')\n",
        "  dateSheet = dSheet.worksheet('Form Responses 1')\n",
        "\n",
        "  return dateSheet#get_as_dataframe(dateSheet)[[\"Start Date\",\"Start Time\",\"Email\",\"Video Count\",\"Queue Name\"]].dropna().drop_duplicates()\n",
        "\n",
        "def getUtilization(ldap):\n",
        "  utilizationTime = 0\n",
        "  #print('utilizationTime time calculating for ldap '+ldap)\n",
        "  try:\n",
        "    ldapLength = len(productivityLdapQDetails[ldap].index.tolist())\n",
        "  except:\n",
        "    ldapLength = 0 \n",
        "  for i in range(0, ldapLength):\n",
        "    q = (productivityLdapQDetails[ldap].index.tolist()[i])\n",
        "    try:\n",
        "      getQueueUtilTime = coreTmDataframe[coreTmDataframe[\"Queuse Name\"] == q][\"AHT\"].iloc[0] \n",
        "    except:\n",
        "     # print('default util time  ')\n",
        "      getQueueUtilTime =0\n",
        "    utilizationTime = float(utilizationTime) + float(getQueueUtilTime) * float(productivityLdapQDetails[ldap][q])\n",
        "    #print('util time  '+str(utilizationTime))\n",
        " \n",
        "  floatVal = float(\"{0:.2f}\".format((utilizationTime/300)*100))\n",
        "  return str(floatVal)+\"%\"\n",
        "\n",
        "def gerQTime(ldap):\n",
        "  try:\n",
        "    return  productivityLdapQDetails[ldap].to_json()  \n",
        "  except:\n",
        "    return 'NA'\n",
        "\n",
        "\n",
        "def getCoreTimeOfLDAP(ldap):\n",
        "  coreTime=0\n",
        "  #print('core time calculating for ldap '+ldap)\n",
        "  try:\n",
        "    ldapLength = len(productivityLdapQDetails[ldap].index.tolist())\n",
        "  except:\n",
        "    ldapLength = 0 \n",
        "  for i in range(0, ldapLength):\n",
        "    q = (productivityLdapQDetails[ldap].index.tolist()[i])\n",
        "    try:\n",
        "      getQueueCoreTime = coreTmDataframe[coreTmDataframe[\"Queuse Name\"] == q][\"ProductiveTime\"].iloc[0] \n",
        "    except:\n",
        "     # print('default core time  ')\n",
        "      getQueueCoreTime =72\n",
        "    coreTime = coreTime + int(getQueueCoreTime) * int(productivityLdapQDetails[ldap][q])\n",
        "   # print('core time  '+str(coreTime))\n",
        " \n",
        "  return coreTime\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8pp0QpmBVAQC",
        "colab_type": "code",
        "outputId": "e97796d5-1c69-40cf-e105-582522b44535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "# insert date wise in google sheet\n",
        "\n",
        "import gspread \n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "\n",
        "queCoreTimeSheet  = gc.open_by_url('https://docs.google.com/spreadsheets/d/13LiUzyVd0eD3zdkExdGFMQo8-Cp9ZkH2TOKfR2ORhVY/edit#gid=142325974')\n",
        "coreTimeQdf = queCoreTimeSheet.worksheet('Sheet2')\n",
        "\n",
        "dateSelected = '01/23/2019'\n",
        "print('sheet created')\n",
        "\n",
        "proddf1 = getProdSheet(dateSelected)\n",
        "\n",
        "productivityLdapQDetails =  get_as_dataframe(proddf1)[[\"Start Time\",\"Email\",\"Video Count\",\"Queue Name\"]].dropna().groupby(['Email','Queue Name'])['Video Count'].sum()\n",
        "coreTmDataframe = get_as_dataframe(coreTimeQdf)[[\"Queuse Name\",\"ProductiveTime\",\"AHT\"]].dropna()\n",
        "\n",
        "\n",
        "print('creating data frame')\n",
        "productivityLdapDetails = get_as_dataframe(proddf1)[[\"Start Time\",\"Email\",\"Video Count\"]].dropna().groupby('Email')['Video Count'].sum()\n",
        "\n",
        "\n",
        "precision = 500\n",
        "datasetfordateselected = getData(dateSelected).dropna()\n",
        "datasetfordateselected['Time in hours'] = datasetfordateselected['Total Time'].apply(lambda x: convertTime(int(x)))\n",
        "\n",
        "datasetfordateselected['Non Productive Time'] = datasetfordateselected['ldap'].apply(lambda ldap: getNonProductiveTime(dateSelected, ldap, 700) )\n",
        "datasetfordateselected['Non Productive Time in Hours'] = datasetfordateselected['Non Productive Time'].apply(lambda x: convertTime(int(x)))\n",
        "\n",
        "\n",
        "\n",
        "datasetfordateselected['Productive Time'] = datasetfordateselected['Total Time'] - datasetfordateselected['Non Productive Time']\n",
        "datasetfordateselected['Productive Time in Hours'] = datasetfordateselected['Productive Time'].apply(lambda x: convertTime(int(x)))\n",
        "print(' Productive Time')\n",
        "datasetfordateselected['Volume Done']  = datasetfordateselected['ldap'].apply(lambda x: getLdapProductivity(x))\n",
        "print(' Volume Done')\n",
        "\n",
        "datasetfordateselected['Avg Core Time']  = datasetfordateselected['ldap'].apply(lambda ldap: getCoreTimeOfLDAP(ldap))\n",
        "datasetfordateselected['Utilization Time']  = datasetfordateselected['ldap'].apply(lambda ldap: getUtilization(ldap))\n",
        "datasetfordateselected['Queue Time Details']  = datasetfordateselected['ldap'].apply(lambda ldap: gerQTime(ldap))\n",
        "#print(qwe)\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sheet created\n",
            "creating data frame\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:104: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Productive Time\n",
            " Volume Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6mGamqJS57Q-",
        "colab_type": "code",
        "outputId": "3d1da122-21e0-49f7-9169-15e9d8467297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2125
        }
      },
      "cell_type": "code",
      "source": [
        "import gspread \n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "pSheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/18_gAPZPQgiipdApSKlz1XwNxh_cbnvCflKCqZy70Xxk/edit#gid=1109981648')\n",
        "wks3 = pSheet.worksheet(dateSelected)\n",
        "datasetfordateselected = datasetfordateselected.dropna()\n",
        "for indx in range(0,len(datasetfordateselected.index.tolist())):\n",
        "  if indx ==0:\n",
        "    listheader = list(datasetfordateselected)\n",
        "    wks3.insert_row(listheader, 1) \n",
        "  else:\n",
        "    print('saving the data for '+datasetfordateselected.iloc[indx-1].ldap)\n",
        "    listrow = list(datasetfordateselected.iloc[indx-1].as_matrix());\n",
        "    listrowstr = [str(i) for i in listrow]\n",
        "    wks3.insert_row(listrowstr, indx+1)\n",
        "\n",
        "lastrow = len(datasetfordateselected.index.tolist())\n",
        "listrow = list(datasetfordateselected.iloc[lastrow-1].as_matrix());\n",
        "listrowstr = [str(i) for i in listrow]\n",
        "wks3.insert_row(listrowstr, lastrow+1)\n",
        "    "
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving the data for iffah\n",
            "saving the data for sirsandi\n",
            "saving the data for nguyennhat\n",
            "saving the data for tkhongjul\n",
            "saving the data for hcheon\n",
            "saving the data for nariaki\n",
            "saving the data for apmrajan\n",
            "saving the data for hoangs\n",
            "saving the data for phuochien\n",
            "saving the data for noorlizab\n",
            "saving the data for utamni\n",
            "saving the data for junehyurk\n",
            "saving the data for thiphuongha\n",
            "saving the data for nphatthalung\n",
            "saving the data for nthanhthuy\n",
            "saving the data for ryalapae\n",
            "saving the data for valpha\n",
            "saving the data for satbyeolj\n",
            "saving the data for miyakem\n",
            "saving the data for seulbee\n",
            "saving the data for romiyah\n",
            "saving the data for yarona\n",
            "saving the data for mabdulroseh\n",
            "saving the data for ihasakanbancha\n",
            "saving the data for nguyenthanht\n",
            "saving the data for lenga\n",
            "saving the data for laimai\n",
            "saving the data for mmohkhwan\n",
            "saving the data for sangillee\n",
            "saving the data for ngocxuansang\n",
            "saving the data for toyokawa\n",
            "saving the data for achimklai\n",
            "saving the data for sfukagawa\n",
            "saving the data for inokuchi\n",
            "saving the data for thilan\n",
            "saving the data for skarim\n",
            "saving the data for vkhang\n",
            "saving the data for achahyun\n",
            "saving the data for kenhock\n",
            "saving the data for nurdiana\n",
            "saving the data for ksunmi\n",
            "saving the data for hathibich\n",
            "saving the data for yunhees\n",
            "saving the data for rchekdaloh\n",
            "saving the data for muhammadr\n",
            "saving the data for cheekent\n",
            "saving the data for wongyu\n",
            "saving the data for mhama\n",
            "saving the data for koyamay\n",
            "saving the data for shrajagopal\n",
            "saving the data for hojunel\n",
            "saving the data for nguyenthup\n",
            "saving the data for hanyeop\n",
            "saving the data for hchealaea\n",
            "saving the data for thuyduong\n",
            "saving the data for dinhbao\n",
            "saving the data for sorakim\n",
            "saving the data for yoonjungc\n",
            "saving the data for haphuong\n",
            "saving the data for nguyentranduy\n",
            "saving the data for tasya\n",
            "saving the data for hayatof\n",
            "saving the data for eunsuc\n",
            "saving the data for zjalil\n",
            "saving the data for bmariam\n",
            "saving the data for nursyazwani\n",
            "saving the data for kiatl\n",
            "saving the data for cherng\n",
            "saving the data for msulong\n",
            "saving the data for muhammadz\n",
            "saving the data for thithuytrang\n",
            "saving the data for mmitpuangchon\n",
            "saving the data for ayusantika\n",
            "saving the data for hannso\n",
            "saving the data for arahmat\n",
            "saving the data for anuarb\n",
            "saving the data for tranthin\n",
            "saving the data for muhammadnur\n",
            "saving the data for suhyeonh\n",
            "saving the data for muhammadha\n",
            "saving the data for thithitho\n",
            "saving the data for junair\n",
            "saving the data for kumardushyant\n",
            "saving the data for lkartina\n",
            "saving the data for thingocloan\n",
            "saving the data for skooswardani\n",
            "saving the data for yamagishim\n",
            "saving the data for rmuhardiman\n",
            "saving the data for wwaearlee\n",
            "saving the data for maisarah\n",
            "saving the data for jiwonkim\n",
            "saving the data for rchareonkarn\n",
            "saving the data for sleearam\n",
            "saving the data for mkhawajausman\n",
            "saving the data for ahmadfa\n",
            "saving the data for mhamyoh\n",
            "saving the data for ssani\n",
            "saving the data for nhuong\n",
            "saving the data for chunwoop\n",
            "saving the data for jongeui\n",
            "saving the data for elferah\n",
            "saving the data for soheec\n",
            "saving the data for yukyung\n",
            "saving the data for makikow\n",
            "saving the data for sugyeongk\n",
            "saving the data for yehxiann\n",
            "saving the data for lsohyun\n",
            "saving the data for choimoon\n",
            "saving the data for fongt\n",
            "saving the data for chyunjun\n",
            "saving the data for jaewoong\n",
            "saving the data for wloong\n",
            "saving the data for saoris\n",
            "saving the data for ranjanalok\n",
            "saving the data for virochan\n",
            "saving the data for vkeshav\n",
            "saving the data for nuzawa\n",
            "saving the data for alfredjulio\n",
            "saving the data for dangq\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '18_gAPZPQgiipdApSKlz1XwNxh_cbnvCflKCqZy70Xxk',\n",
              " 'updatedCells': 13,\n",
              " 'updatedColumns': 13,\n",
              " 'updatedRange': \"'01/23/2019'!A121:M121\",\n",
              " 'updatedRows': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "metadata": {
        "id": "gpRRpFd0WMFP",
        "colab_type": "code",
        "outputId": "fa560df2-78b8-4ee1-dd50-e92b0e930f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "cell_type": "code",
      "source": [
        "#Insert into Google Sheet\n",
        "\n",
        "import gspread \n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "#productivitySheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/18_gAPZPQgiipdApSKlz1XwNxh_cbnvCflKCqZy70Xxk/edit#gid=0')\n",
        "productivitySheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/18_gAPZPQgiipdApSKlz1XwNxh_cbnvCflKCqZy70Xxk/edit#gid=1318935553')\n",
        "wks = productivitySheet.worksheet('Jan1-15 Datewise Details')\n",
        "for indx in range(0,len(productivityFrame.index.tolist())):\n",
        "  if indx ==0:\n",
        "    listheader = list(productivityFrame)\n",
        "    wks.insert_row(listheader, 1) \n",
        "  else:\n",
        "    listrow = list(productivityFrame.iloc[indx-1].as_matrix());\n",
        "    listrowstr = [str(i) for i in listrow]\n",
        "    wks.insert_row(listrowstr, indx+1)\n",
        "\n",
        "lastrow =len(productivityFrame.index.tolist())\n",
        "listrow = list(productivityFrame.iloc[lastrow-1].as_matrix());\n",
        "listrowstr = [str(i) for i in listrow]\n",
        "wks.insert_row(listrowstr, lastrow+1)\n",
        "\n",
        "wks2 = productivitySheet.worksheet('Jan1-15 LDAPwise Details')\n",
        "for indx in range(0,len(productivityDataFrame.index.tolist())):\n",
        "  if indx ==0:\n",
        "    listheader = list(productivityDataFrame)\n",
        "    wks2.insert_row(listheader, 1) \n",
        "  else:\n",
        "    listrow = list(productivityDataFrame.iloc[indx-1].as_matrix());\n",
        "    listrowstr = [str(i) for i in listrow]\n",
        "    wks2.insert_row(listrowstr, indx+1)\n",
        "\n",
        "lastrow =len(productivityDataFrame.index.tolist())    \n",
        "listrow = list(productivityDataFrame.iloc[lastrow-1].as_matrix());\n",
        "listrowstr = [str(i) for i in listrow]\n",
        "wks2.insert_row(listrowstr, lastrow+1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "WorksheetNotFound",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gspread/models.py\u001b[0m in \u001b[0;36mworksheet\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'properties'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                 \u001b[0msheet_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sheets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gspread/utils.py\u001b[0m in \u001b[0;36mfinditem\u001b[0;34m(func, seq)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \"\"\"\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mWorksheetNotFound\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-13037a6cf041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#productivitySheet = gc.open_by_url('https://docs.google.com/spreadsheets/d/18_gAPZPQgiipdApSKlz1XwNxh_cbnvCflKCqZy70Xxk/edit#gid=0')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mproductivitySheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_by_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://docs.google.com/spreadsheets/d/18_gAPZPQgiipdApSKlz1XwNxh_cbnvCflKCqZy70Xxk/edit#gid=1318935553'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mwks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproductivitySheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Jan1-15 Datewise Details'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproductivityFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mindx\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gspread/models.py\u001b[0m in \u001b[0;36mworksheet\u001b[0;34m(self, title)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mWorksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'properties'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWorksheetNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_worksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWorksheetNotFound\u001b[0m: Jan1-15 Datewise Details"
          ]
        }
      ]
    }
  ]
}